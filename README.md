# Parallel Programming Final Project: Distributed Model Training with MPI

This repository contains the final project for a course in parallel programming, focusing on distributed model training using the Message Passing Interface (MPI). The project extends the [DeepPurpose](https://github.com/kexinhuang12345/DeepPurpose) framework developed by kexinhuang12345, integrating multi-node capabilities to enhance drug-target interaction (DTI) prediction models.

## Project Overview

In our project, we implemented the `mpi_train` function in the `DTI.py` script of the DeepPurpose framework to enable distributed training across multiple nodes. This approach aims to improve the training efficiency and scalability of the DTI models.

## Documentation

- **Midterm Proposal:** Our initial project proposal, outlining the project goals and preliminary methods, is available [here](https://drive.google.com/file/d/1DiFJuO3ZQl-2dqWUcoBkyxQ-LxCZ9mj4/view?usp=sharing).
- **Final Paper Report:** Our comprehensive report, titled "Distributed Model Training with MPI for Multi-Node Training," details the methodologies, results, and conclusions of our distributed training implementation. It can be accessed [here](https://drive.google.com/file/d/1AoI7ifno8WEhKCrCoMWZ60yQOfR6pqHy/view?usp=sharing).
